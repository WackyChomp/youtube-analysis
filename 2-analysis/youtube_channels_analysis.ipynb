{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Exploratory Analysis of YouTube Channels and Videos Based on Educational and Entertainment Content</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction | Objectives | Approach | Data Source\n",
    "\n",
    "## 1.1. Introduction\n",
    "\n",
    "---YouTube Background info---\n",
    "\n",
    "YouTube had it's humble beginnings starting out in\n",
    "\n",
    "The first video uploaded was [Me at the zoo](https://www.youtube.com/watch?v=jNQXAC9IVRw). \n",
    "\n",
    "---YouTube Accomplishments---\n",
    "\n",
    "---My Motivations---\n",
    "\n",
    "I have been utilizing YouTube as a main source of entertainment and educational content for over a decade. This is my first instance of taking a deeper look at the statistics of top content creators I have followed previously, ocassionally, or currently. This project explores the educational and entertainment content from 10-20 successful YouTube channels.\n",
    "\n",
    "\n",
    "## 1.2. Objectives\n",
    "\n",
    "The project will strengthen my understanding and explores the following:\n",
    "\n",
    "- Learning Youtube API | Navigating documentation | Obtaining video data\n",
    "- Analyzing common misconceptions of becoming <b>\"successful\"</b> on YouTube\n",
    "- Identify trending topics through Natural Language Processing (NLP) approaches\n",
    "\n",
    "\n",
    "## 1.3. Approach\n",
    "1. Obtain meta data with Youtube API from 10-15 channels in entertainment and education niches\n",
    "2. Cleaning raw data and develop additional features for analysis (Pandas)\n",
    "3. Exploratory analysis with data visualizations (Seaborn | Matplotlib)\n",
    "4. Conclusions / Findings\n",
    "\n",
    "\n",
    "## 1.4. Data Source\n",
    "- Existing datasets online do not have the necessary information to perform exploratory analysis in this project. Some reasons include:\n",
    "  - Outdated information\n",
    "- Currently YouTube API service retains information from the past 30 days. The only way\n",
    "to have more statistics beyond 30 days is to continuously scrape data until the information is required in the future.\n",
    " - The downside of this approach growing collection of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from googleapiclient.discovery import build\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "from IPython.display import JSON\n",
    "\n",
    "\n",
    "# Data visualization packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "# Loading environment variable\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# API_Key\n",
    "api_key = os.environ.get('YOUTUBE_API_KEY')\n",
    "\n",
    "\n",
    "# Example list of channel IDs\n",
    "CHANNEL_IDS = [\n",
    "  \"UCX6OQ3DkcsbYNE6H8uQQuVA\",     # Mr Beast\n",
    "  \"UC-lHJZR3Gqxm24_Vd_AJ5Yw\",     # PewDiePie\n",
    "  \"UCINb0wqPz-A0dV9nARjJlOQ\",     # The Dodo\n",
    "  \"UCshoKvlZGZ20rVgazZp5vnQ\",     # CaptainSparklez\n",
    "  \"UCY1kMZp36IQSyNx_9h4mpCg\",     # Mark Rober\n",
    "  \"UC6nSFpj9HTCZ5t-N3Rm3-HA\",     # Vsauce\n",
    "  \"UCiDJtJKMICpb9B1qf7qjEOA\",     # Adam Savage's Tested\n",
    "  \"UCsXVk37bltHxD1rDPwtNM8Q\",     # Kurzgesagt – In a Nutshell\n",
    "  \"UCAL3JXZSzSm8AlZyD3nQdBA\",     # Primitive Technology\n",
    "]\n",
    "\n",
    "SMALL_CHANNEL_IDS = [\n",
    "  \"UCX6OQ3DkcsbYNE6H8uQQuVA\",     # Mr Beast\n",
    "  \"UCY1kMZp36IQSyNx_9h4mpCg\",     # Mark Rober\n",
    "  \"UC6nSFpj9HTCZ5t-N3Rm3-HA\",     # Vsauce\n",
    "  \"UCsXVk37bltHxD1rDPwtNM8Q\",     # Kurzgesagt – In a Nutshell\n",
    "  \"UCAL3JXZSzSm8AlZyD3nQdBA\",     # Primitive Technology\n",
    "]\n",
    "\n",
    "\n",
    "# Example playlist of all videos \n",
    "# ****Helpful -- (replace \"UC\" string from beginning of Channel Id with \"UU\")****\n",
    "# https://www.youtube.com/playlist?list=\n",
    "PLAYLIST_IDS = [\n",
    "  'UUX6OQ3DkcsbYNE6H8uQQuVA'                # Mr Beast\n",
    "  'PLoSWVnSA9vG9qV0CVCpg5WwEy3LiP7udY',     # Mr Beast (new uploads)\n",
    "  'UULF-lHJZR3Gqxm24_Vd_AJ5Yw',             # PewDiePie\n",
    "  'UUINb0wqPz-A0dV9nARjJlOQ',               # The Dodo\n",
    "  'UUshoKvlZGZ20rVgazZp5vnQ',               # CaptainSparklez\n",
    "  \"UUY1kMZp36IQSyNx_9h4mpCg\",               # Mark Rober\n",
    "  \"UU6nSFpj9HTCZ5t-N3Rm3-HA\",               # Vsauce\n",
    "  \"UUiDJtJKMICpb9B1qf7qjEOA\",               # Adam Savage's Tested\n",
    "]\n",
    "\n",
    "SMALL_PLAYLIST_IDS = [\n",
    "  'UUX6OQ3DkcsbYNE6H8uQQuVA'                # Mr Beast\n",
    "  'PLLoPYaJqlcK623-8kR0vVuwW_vaR2k1zE',               # The Dodo faith restored\n",
    "  \"UUY1kMZp36IQSyNx_9h4mpCg\",               # Mark Rober\n",
    "  \"UU6nSFpj9HTCZ5t-N3Rm3-HA\",               # Vsauce\n",
    "]\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "youtube = build(api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Basic Channel Stats\n",
    "Looking at immediate/common information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, SMALL_CHANNEL_IDS):\n",
    "  all_channel_data = []\n",
    "\n",
    "  # https://developers.google.com/youtube/v3/docs/channels/list\n",
    "  request = youtube.channels().list(\n",
    "    part = 'snippet, contentDetails, statistics',\n",
    "    id= ','.join(SMALL_CHANNEL_IDS)\n",
    "  )\n",
    "  response = request.execute()\n",
    "\n",
    "  # https://developers.google.com/youtube/v3/docs/channels\n",
    "  for item in response['items']:\n",
    "    data = {\n",
    "      'channelName': item['snippet']['title'],\n",
    "      'creationDate': item['snippet']['publishedAt'],\n",
    "      'subscribers': item['statistics']['subscriberCount'],\n",
    "      'channelViews': item['statistics']['viewCount'],\n",
    "      'totalVideos': item['statistics']['videoCount'],\n",
    "      'playlistId': item['contentDetails']['relatedPlaylists']['uploads'],\n",
    "    }\n",
    "\n",
    "    all_channel_data.append(data)\n",
    "\n",
    "  return(pd.DataFrame(all_channel_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_test_channels_stats = get_channel_stats(youtube, SMALL_CHANNEL_IDS)\n",
    "quick_test_channels_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Video IDs\n",
    "This step is crucial as it narrows down where to focus on. Before collecting video Ids, we need to obtain a playlist Id.\n",
    "\n",
    "On YouTube, an owner's channel has the liberty to create a playlist of videos they have uploaded or videos uploaded by other channels. In this analysis, we will use the default playlist \"all uploads\". We can obtain this playlist Id by swapping the beginning of the channel Id \"UC\" with \"UU\" [<b>REFER TO CELL 1 ABOVE</b>]\n",
    "\n",
    "Sometimes we do not want all video uploads playlist. Instead, we can use other playlists granted if owner created or not privated them.\n",
    "<br>*---Important: Channel owner can create a playlist of videos that are not uploaded by themselves / Carefully look at the uploader of video---*\n",
    "\n",
    "After choosing a playlist, we finally proceed to obtaining video ids. Each video has its own unique id for conclusive identification. Having a playlist ensures that all the videos uploaded from the channel owner is related and theirs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ***Note: This is only needed if you want to see how many videos/video ids are in a single playlist\n",
    "#playlist_id = \"UUY1kMZp36IQSyNx_9h4mpCg\"      # \"UUY1kMZp36IQSyNx_9h4mpCg\"\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "  video_ids = []\n",
    "\n",
    "  request = youtube.playlistItems().list(\n",
    "  part='snippet,contentDetails',\n",
    "  playlistId=playlist_id,\n",
    "  maxResults=50       # default is 5 video ids\n",
    "  )\n",
    "  response = request.execute()\n",
    "\n",
    "  for item in response['items']:\n",
    "    video_ids.append(item['contentDetails']['videoId'])\n",
    "  \n",
    "  next_page_token = response.get('nextPageToken')\n",
    "  while next_page_token is not None:\n",
    "    request = youtube.playlistItems().list(\n",
    "      part='snippet,contentDetails',\n",
    "      playlistId=playlist_id,\n",
    "      maxResults=50,       # default is 5 video ids\n",
    "      pageToken = next_page_token\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    for item in response['items']:\n",
    "      video_ids.append(item['contentDetails']['videoId'])\n",
    "\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "\n",
    "  return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_ids = get_video_ids(youtube, playlist_id)\n",
    "# len(video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Video Information\n",
    "After collecting specific video ids, we can finally dive deeper into the videos themselves and look at the finer details\n",
    "\n",
    "Each meta data falls under a certain category\n",
    "Using the following: [--Insert link--], we are able to specify which data/item to request through the YouTube API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "  all_video_info = []\n",
    "\n",
    "  for i in range(0, len(video_ids), 50):\n",
    "    request = youtube.videos().list(\n",
    "      part='snippet,contentDetails,statistics',\n",
    "      id=','.join(video_ids[i:i+50])\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    for video in response['items']:\n",
    "      intended_stats = {\n",
    "        'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "        'contentDetails': ['duration', 'definition', 'caption'],\n",
    "        'statistics': ['viewCount', 'likeCount', 'favoriteCount', 'commentCount']\n",
    "      }\n",
    "\n",
    "      video_info = {}\n",
    "      video_info['video_id'] = video['id']\n",
    "\n",
    "      for k in intended_stats.keys():\n",
    "        for v in intended_stats[k]:\n",
    "          try:\n",
    "            video_info[v] = video[k][v]\n",
    "          except:\n",
    "            video_info[v] = None\n",
    "\n",
    "      all_video_info.append(video_info)\n",
    "\n",
    "  return pd.DataFrame(all_video_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataframe is accessible after uncommenting codes under \"Obtaining Video IDs\" section\n",
    "# This shows all video ids in single playlist\n",
    "\n",
    "# video_info_df = get_video_details(youtube, video_ids)\n",
    "# video_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = get_channel_stats(youtube, SMALL_CHANNEL_IDS)\n",
    "channel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending all videos from different channels together\n",
    "<p>The joy of fusing all the video data together!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_df = pd.DataFrame()\n",
    "\n",
    "for c in channel_data['channelName'].unique():\n",
    "\tprint(\"Getting video information from channel: \" + c)\n",
    "\tplaylist_id = channel_data.loc[channel_data['channelName']== c, 'playlistId'].iloc[0]\n",
    "\tvideo_ids = get_video_ids(youtube, playlist_id)\n",
    "\n",
    "\t# get video data\n",
    "\tvideo_data = get_video_details(youtube, video_ids)\n",
    "\n",
    "\n",
    "\t# append video data together and comment data toghether\n",
    "\t#video_df = video_df.append(video_data, ignore_index=True)\n",
    "\t#video_df = pd.concat([video_df, pd.DataFrame([video_data])]), ignore_index=True)\n",
    "\tvideo_df = video_df._append(video_data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Process / Cleaning Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Types\n",
    "print(video_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Values\n",
    "print(video_df.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the following table headers to numerical data type\n",
    "# (from --- parameter part: statistics)\n",
    "numeric_cols = ['viewCount', 'likeCount', 'favoriteCount', 'commentCount']\n",
    "video_df[numeric_cols] = video_df[numeric_cols].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make video duration more clear (days / hour:minute:seconds)\n",
    "import isodate\n",
    "video_df['durationSecs'] = video_df['duration'].apply(lambda x :isodate.parse_duration(x))\n",
    "video_df['durationSecs'] = video_df['durationSecs'].astype('timedelta64[s]')\n",
    "\n",
    "video_df[['duration', 'durationSecs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"day\" and \"month\" columns based on publish date\n",
    "video_df['dayPublished'] = pd.to_datetime(video_df['publishedAt']).dt.strftime('%a')\n",
    "video_df['monthPublished'] = pd.to_datetime(video_df['publishedAt']).dt.strftime('%b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-yt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
